# Parallel Computing Coursework

Name: Josh Everett

URN: 6621182



## Question 1

#### a. **What is the “>>” operator?**

The “>>” operator is a right bit shift operation that shifts the operands (number to the left of the operator) bits to the right by the number to the right of the operator. Excess bits shifted off to the right are discarded.

A single bit shift will half the operand, the number of bit shifts made will cause the operand to half that many times as binary is base 2. 

For example 12 >> 2 will cause a bit shift of 2 shifts to the right, after the single bit shift the 12 would be halfed to 6 then after the second bit shift 6 will half to become 3.

This can be visualised:

0000 1100  = 12

If we shift the bits to the right we will get

0000 0110 = 6

Then when we shift to the right again we will get

0000 0011 = 3

#### b. **Ignoring overheads due to memory access and task communication, calculate the pessimistic and optimistic estimates of overall speedup (up to 2 decimal places) for the case where 75% of the work in a task is sped up by the use of 1000 parallel processors.**

Using Amdahl’s Law we can use the following equation
$$
pessimistic = \frac{1}{1 - 0.75 + \frac{0.75}{1000}} = 3.98
$$

s = 1 / (0.75 / 1000 + (1-0.75)) = 3.99



**pessimistic = 3.99 times (2dp)**
$$
optimistic = 1 - p + sp = 1 - (0.75) + 1000(0.75) = 750.25
$$
**optimistic 750.20 times (2dp)**

**ANS:**

$optimistic = 750.25$

$pessimistic = 3.98$



#### c. **Assuming that that a kernel called someKernel has been defined, how many times will it run based on the following invocation: someKernel<<<10, 10>>>()**

The following invocation is configured to run in 10 thread blocks which each have 10 threads and will therefore run 100 times.

10 threads per block and 10 blocks.

The kernel will be ran on 10 threads on each block, block 1 will run 10 times, block 2 will run 10 times … and so on. This will happen until block 10 has been ran and the total number of times the kernel was run was 100 times.

#### d. **What is the arithmetic intensity of the matrix multiplication kernel using shared memory (Lab class week 3)?**

Arithmetic intensity is the ratio of the floating point operations / sec to the bytes.



$$
Arithmetic\ Intensity = \frac{number\ of\ FLOPS}{number\ of\ byte\ accesses} = \frac{A.width\ multiplications + A.width\ additions}{2*(A.width)\ shared\ memory\ reads + A.width\ global\ memory\ reads }
$$
**Block size = 16**, taken from lab 3 `#define BLOCK_SIZE 16`

**Number of flops:**

For matrix multiplication each element in the width will be multiplied by the height of the other matrix (they should be the same number), therefore if the block size is 16, there will be 16 multiplications.

After the multiplication each one needs to be added together, this means there will be 16 additions. So there will be 16 + 16 operations. 

Number of flops to multiply 2 matricies (using lab 3 block size) = **32**.

**Number of byte accesses:**

In the lab example there are 2 shared memory arrays created, these are read from BLOCK_SIZE number of times each and as BLOCK_SIZE = 16, there will be 32 memory reads.  There will be 16 global memory reads in the kernel.

Number of shared memory reads + global memory reads = **48**.

**Arithmetic intensity:**

Therefore the fomula required will be:
$$
\frac{16 + 16} {(2* 16) + 16} = \frac{32}{32 + 16} = 0.67
$$




#### e. **Assume that we want to use each thread to calculate two (adjacent) elements of a vector addition. What would be the expression for mapping the thread/block indices to i, the data index of the first element to be processed by a thread?**

**I. i=blockIdx.x * blockDim.x + threadIdx.x +2;
II. i=blockIdx.x * threadIdx.x * 2
III. i=(blockIdx.x * blockDim.x + threadIdx.x)*2
IV. i=blockIdx.x * blockDim.x * 2 + threadIdx.x**

Because the elements of the vectors are adjancent they cover 2 consecutive elements, the first element would be 2 times the global thread index.

**Ans = III**

#### (f) If a CUDA device’s SM (streaming multiprocessor) can take up to 1536 threads and up to 4 thread blocks. Which of the following block configuration would result in the most number of threads in the SM? [4] 

###### I. 128 threads per block 

###### II. 256 threads per block 

###### III. 512 threads per block 

###### IV. 1024 threads per block 

We have a maximum of 1536 threads and up to 4 thread blocks.

So the maximum number of threads per block = 1536 / 4 = 384 threads per block.

Therefore out of the configurations above the one that would use the most threads that is under the maximum would be **256 threads per block.**

**ANS = II**

**(g) In order to write a kernel that operates on an image of size 400x900 pixels, you would like to assign one thread to each pixel. You would like your thread blocks to be square and to use the maximum number of threads per block possible on the device (your device has maximum number of threads per block as 1024). How would you select the grid dimensions and block dimensions of your kernel? [6]**

**How we determine the block dimensions of the kernel**

If the maximum number of threads per block is 1024, this is the same as saying that the maximum block size is 1024.

Because the image is 2D we need to make sure that that the product of the  block dimensions does not exceed the maximum block size / number of threads (1024) because each pixel will be given a thread in the block and we need to divide the block dimensions so there is the same number in each.

Also the question states that the blocks should be *“Square”* the $x,y$ dimensions should be the same.

Therefore a valid block size is one where the product of the sides do not exceed the limit of the block size and the dimensions of the block kernel are the same. Therefore a valid block dimension of the kernel could be 32 x 32.

The way that I would calculate the block size would be to check to see if I can use the square root as it would be the perfect size. 

$\sqrt{1024} = 32$

This is the perfect for the block dimensiosn of the kernel.

**BLOCK SIZE = 32, 32**

**How we determine the grid dimensions of the kernel**

If we want to map a thread for every pixel then the total number of threads in each dimension should be at least equal to the corresponding image dimension. This means the total number of threads in a dimension is equal to the product of grid size and block size in that dimension.

Because the image size is (400x900) pixels the total number of threads in the corresponding dimension **should be the at the very least, the same but can be larger.**

The number of blocks in each dimension would be dimension pixel size / dimension block size. 

x = 400 / 32 = 12.5 so we ceil the result (round up) to get 13.
y = 900 / 32 = 28.125 so we ceil the result (round up) to get 29.

Grid size will be 13 * 29 so total number of threads will be 416 * 928.

Because the grid size will cause the total number of threads to be larger than the total number of pixels I would implement checks to make sure that thread is within the bounds of the dimensions of the image.

**GRID DIMENSIONS = 13 * 29**

**OVERALL ANS:**

**GRID DIMENSIONS = (13 x 29)**

**BLOCK SIZE = (32 x 32)**

## Question 2

See files:

a. **Q2a_6621182.cu**

b. **Q2b_6621182.cu**

c. **Q2c_6621182.cu**

d. **Q2d_6621182.cu**

e. **Q2e_6621182.cu**



## Question 3

![image-20220502112222897](/user/HS402/je00452/Desktop/Parallel Computing Coursework/report_6621182.assets/image-20220502112222897.png)

The question defines the nodes on the graph are equally weighted. For simplicity I will assume that each node has a weight of 1. The answers below be using that assumption. 

#### a. **Left image**

​	i. **Maximum degree of concurrency** - The maximum number of concurrent operations that can occur

There are 8 child nodes of the root node therefore 8 nodes that can run concurrent operations. This is the maximum degree of concurrency.

**ANS = 8**

​	ii. **Critical path length** - The sum of weights of nodes along critical path.

There are 7 nodes that are on the critical path - the root node and the 6 other nodes that extend down from that. 

**ANS = 7**

iii. **Average degree of concurrency (express this as a ratio)** - Total amount of work / critical path length

There are 14 nodes therefore toal work = 14, the critical path length is 7, so average degree of concurrency = **14 / 7** 

**ANS = 14 / 7 = 2**

#### b. **Right image**

​	i. **Maximum degree of concurrency** - The maximum number of concurrent operations that can occur

With eager scheduling there are 2 nodes that are children of the parents therefore maximum degree of concurrency is 2. Without using the eager scheduling the maximum degree of concurrency is 8 as there are 8 possible nodes that can perform concurrent operartions.

**ANS = 2 with eager scheduling, 8 otherwise** 

​	ii. **Critical path**  - The sum of weights of nodes along critical path.

Along the critical path (the right path) there are 8 nodes which is the critical path.

**ANS = 8** 

​	iii. **Average degree of concurrency (express this as a ratio)** - Total amount of work / critical path length

**ANS = 15 / 8 = 1.875**

## Question 4

a. See file **Q4a_6621182.cu**

**b. How many global memory reads and writes are performed by your kernel? Explain**

The kernel will be ran GRID_SIZE * BLOCK_SIZE. Each time my kernel is run it reads (size of input array / grid size) number of times, by adding the value into a sum variable. Therefore **reads = BLOCK_SIZE**

Then my kernel writes the output list when the thread id is 0 in each block - only 1 thread per block will have the id of 0 therefore the number times that is global memory will be written to GRID_SIZE or the number of blocks.

**Therefore writes = GRID_SIZE** or **number of blocks**

With values: 

If the **block size is 8** and the **input array size is 4096.** The **grid size is 4096 / 8 = 512**.

Kernel is running 512 * 8 = 4096 times.

Each time we are making 4096 / 512 = **8 reads**

#include <stdio.h>
 * Question 4

/*
 * Provide a complete implementation of a parallel algorithm that
 * will Reduce a 1D array of elements into a single summary value,
 * where the size of the input array will require the use of multiple
 * blocks of threads. The reduction should give the sum of the list.
 *
 * Below there is a definition of the number of elements in the
 * input array. Just change that number to change the size of the
 * input array.
*/
#define InputArraySize 4096


/*
 * Definition for global varibles that can be changed.
 */

// Represents the number of threads in each block.
#define BLOCK_SIZE 8

static int readCount = 0;

/*
 * Function that will perform reduction on sections of the input array.
 *
 * sizeOfArray - the length of the array [idata]
 *
 * idata - a pointer to the integer array of numbers that are being reduced
 *
 * odata - a pointer to the integer array of sums of sections of the input array.
 *
 * The purpose of the reduceKernel function is to reduce a 1D array into a single
 * summation of the integer elements of the array.
 *
 * This can run on multiple blocks of threads that can be customised using the
 * global definitions above.
 *
  */
 __global__ void reduceKernel(int sizeOfArray, int *idata, int *odata);

/*
 * Sum array function that is defined with __host__ to tell the compiler that the function should
 * be ran on the CPU.
 *
 * This function receives a pointer to an integer array.
 *
 * The purpose of this function is handle calling the reduceKernel function and to sum
 * each of the sections returned by the reduceKernel function.
 *
 * This function is responsible for handling the memory allocation for the different lists that it
 * makes
 */
 __host__ int sumArray(int* arr );

/**
 * Definition of the error handling functions
 *
  */
 #define CudaSafeCall( err ) __cudaSafeCall( err, __FILE__, __LINE__ )

/**
 * Function accepts a cuda error, file and line
 *
 * This will check that the err property was not a success and if so will output the error
 * that was returned.
 *
 * This is intended to be used to handle errors thrown by functions such as cudaMalloc / cudaMallocManaged etc.
 */
 inline void __cudaSafeCall(cudaError err, const char *file, const int line)
 {
	if(cudaSuccess != err)
	{
		fprintf( stderr, "cudaSafeCall() failed at %s:%i : %s\n",
				file, line, cudaGetErrorString( err ) );
		exit( -1 );
	}
 }



/*
 * The main function that will run when the function is compiled.
 *
	 */
	int main(void)
	{

	// Create a pointer to an array of integers and store in variable idata (input data).
	int *idata;

	//Allocate Unified Memory -- accessible from CPU and GPU
	//nice and simple, but it does mean that the
	// input array is overwritten to provide the result

	// Wrapping this in a CudaSafeCall function to handle the error if one is thrown.
	CudaSafeCall(cudaMallocManaged(&idata, InputArraySize*sizeof(int)));


	printf("Allocated memory %ld bytes to the array data.\n", InputArraySize*sizeof(int) );
	
	//Initialise the input data on the host
	//Making it easy to test the result
	for(int i=0; i < InputArraySize; i++)
	{
		idata[i] = i;
	}
	
	printf("Populated array data with values up from 0 to %d.\n", InputArraySize);
	
	// Call the sumArray function passing in the idata array to reduce the array
	// and store the result in the variable sum.
	
	int sum = sumArray(idata);
	
	//Now output the result of the reduction.
	printf("The final reduction is: %d\n", sum); //the reduced sum is contained
	
	//in index 0 of the array
	printf("\n");
	
	//Free all allocated memory
	
	// Wrapping this in a CudaSafeCall function to handle the error if one is thrown.
	CudaSafeCall(cudaFree(idata));
	
	// Return 0 to show that the program executed successfully.
	return 0;
}

__host__ int sumArray(int* arr )
{

	// Dynamic grid size so that the grid size can be dependent depending on the size of the input array and the block size
	// makes it more efficient.
	int grid_size = ceil(static_cast< int >(InputArraySize)/BLOCK_SIZE);
	
	// Define the variable that will hold the sum that will be returned.
	int sum = 0;
	
	/*
	 *  Create a pointer to an integer array in the variable dev_out.
	 *
	 *  This array will be an array that will contain the ongoing sum
	 *  of the array for each section of the sum.
	 *
	 *  The contents of this array will summed by the CPU to get the final
	 *  reduction.
	 *
	 */
	int* dev_out;
	
	// Allocate memory to the dev_out array at the size of the grids.
	
	// Wrapping this in a CudaSafeCall function to handle the error if one is thrown.
	CudaSafeCall(cudaMallocManaged(&dev_out, sizeof(int)* grid_size));


	// Call the reduce kernel function to get the partial results of the sum.
	reduceKernel<<<grid_size, BLOCK_SIZE>>>(InputArraySize, arr, dev_out);
	
	//dev_out now holds the partial result
	
	// Synchronise the device
	// Wrapping this in a CudaSafeCall function to handle the error if one is thrown.
	CudaSafeCall(cudaDeviceSynchronize());
	
	// Performing the final reduction on the CPU as only 1 kernal call was allowed.
	for (int i = 0; i < grid_size; i++){
		// Adds the element of the array to the sum
		sum += dev_out[i];
	}
	
	// Free up the memory allocated to the dev_out array.
	
	// Wrapping this in a CudaSafeCall function to handle the error if one is thrown.
	CudaSafeCall(cudaFree(dev_out));
	
	// Return the resultant sum to the caller (main function).
	return sum;
}

__global__ void reduceKernel(int sizeOfArray, int *idata, int *odata)
{

	// mapping the local thread index onto the index
	//of the array element we are going to be working on.
	int tid = threadIdx.x;
	
	// mapping the local grid index that is being worked on.
	int gid = tid + blockIdx.x * BLOCK_SIZE;
	
	// Defining the grid size
	const int gridSize = BLOCK_SIZE * gridDim.x;
	
	// temporary sum of the section.
	int sum = 0;
	// For each of the grids sum its section of the input array
	for (int i = gid; i < sizeOfArray; i += gridSize) {
		sum += idata[i];
	}
	
	// Create a shared integer array with the size of the block
	__shared__ int shArr[BLOCK_SIZE];
	shArr[tid] = sum;
	
	// Sync the threads of the block
	__syncthreads();
	
	//do reduction
	// define the stride ‘stride’, start off with s equal to half the block size,
	// with each step through the for-loop, s is reduced to half of its previous value
	//by using the right-shift (>>) operator
	for( int stride=BLOCK_SIZE/2; stride>=1; stride>>=1){
		if(tid < stride){
			//get the value of the array element the thread is working on &
			//add to it the value of its neighbour ‘s’ elements away. Store it
			// in the shared array at the index of the current thread variable to avoid race condition
			 shArr[tid] += shArr[tid + stride];
	
		}
	
		// After the read, do barrier synchronisation to synch threads
		// to make sure all adds at one stage are done
		__syncthreads();


	}
	
	// Update the value of the array element the thread is working on
	// with the value of temp
	// only ran when the thread id is 0.
	if (tid == 0){
		odata[blockIdx.x] = shArr[0];
	}
	
	//Once we have iterated through the for-loop, we will be left with the reduced value,
	//which is in the one belonging to thread index 0, i.e. at data (input array) index 0.
}The thread id will be 0 4096 times therefore will be **written to 4096 times**.



**c. Describe what optimizations were performed to your kernel to achieve a performance speedup.**

I used shared memory within each block to speed up the memory accesses to reduce the number of global memory reads as its slower than reading/writing to shared memory.

I am using sequential addressing in my implementation to speedup the performance instead of using interleaved addressing as it has a larger bandwidth and faster execution time.

**d. Describe what further optimizations can be implemented to your kernel to achieve a performance speedup.**

Further improvements that I could implement to achieve an increase in performance are adding a first add during the global load. Currently in my implementation half of the threads are idle on the first loop if the iteration, loading 2 times the .

Another improvement is due to the relatively large bandwidth rovided by the sequential addressing and a relatively low number of operations, the arithmetic intensity of the reduction will be relatively low therefore  a bottlencck is most likely being introduced. Therefore to improve the performance we can unroll the last wrap of the reduction loop. This saves on useless work in all warps and will increase the performance of the reduction.

