# Parallel Computing Coursework

Name: Josh Everett

URN: 6621182



## Question 1

#### a. **What is the “>>” operator?**

The “>>” operator is a right bit shift operation that shifts the operands (number to the left of the operator) bits to the right by the number to the right of the operator. Excess bits shifted off to the right are discarded.

A single bit shift will half the operand, the number of bit shifts made will cause the operand to half that many times as binary is base 2. 

For example 12 >> 2 will cause a bit shift of 2 shifts to the right, after the single bit shift the 12 would be halfed to 6 then after the second bit shift 6 will half to become 3.

This can be visualised:

0000 1100  = 12

If we shift the bits to the right we will get

0000 0110 = 6

Then when we shift to the right again we will get

0000 0011 = 3

#### b. **Ignoring overheads due to memory access and task communication, calculate the pessimistic and optimistic estimates of overall speedup (up to 2 decimal places) for the case where 75% of the work in a task is sped up by the use of 1000 parallel processors.**

Using Amdahl’s Law we can use the following equation
$$
pessimistic = \frac{1}{1 - 0.75 + \frac{0.75}{1000}} = 4.98
$$



**pessimistic = 4.98 times (2dp)**
$$
optimistic = 1 - p + sp = 1 - (0.8) + 1000(0.8) = 800.20
$$
**optimistic 800.20 times (2dp)**

**ANS:**

$optimistic = 800.20$

$pessimistic = 4.98$



#### c. **Assuming that that a kernel called someKernel has been defined, how many times will it run based on the following invocation: someKernel<<<10, 10>>>()**

The following invocation is configured to run in 10 thread blocks which each have 10 threads and will therefore run 100 times.

10 threads per block and 10 blocks.

The kernel will be ran on 10 threads on each block, block 1 will run 10 times, block 2 will run 10 times … and so on. This will happen until block 10 has been ran and the total number of times the kernel was run was 100 times.

#### d. **What is the arithmetic intensity of the matrix multiplication kernel using shared memory (Lab class week 3)?**

Arithmetic intensity is the ratio of the floating point operations / sec to the bytes.



$\frac{A.width\ multiplications\ +\ A.width\ additions}{2(A.width)\ reads\ from\ shared\ memory\ +\ A.width\ global\ memory\ access}$



#### e. **Assume that we want to use each thread to calculate two (adjacent) elements of a vector addition. What would be the expression for mapping the thread/block indices to i, the data index of the first element to be processed by a thread?**

**I. i=blockIdx.x * blockDim.x + threadIdx.x +2;
II. i=blockIdx.x * threadIdx.x * 2
III. i=(blockIdx.x * blockDim.x + threadIdx.x)*2
IV. i=blockIdx.x * blockDim.x * 2 + threadIdx.x**

Because the elements of the vectors are adjancent they cover 2 consecutive elements, the first element would be 2 times the global thread index.

**Ans = III**

#### (f) If a CUDA device’s SM (streaming multiprocessor) can take up to 1536 threads and up to 4 thread blocks. Which of the following block configuration would result in the most number of threads in the SM? [4] 

###### I. 128 threads per block 

###### II. 256 threads per block 

###### III. 512 threads per block 

###### IV. 1024 threads per block 

We have a maximum of 1536 threads and up to 4 thread blocks.

So the maximum number of threads per block = 1536 / 4 = 384 threads per block.

Therefore out of the configurations above the one that would use the most threads that is under the maximum would be **256 threads per block.**

**ANS = II**

**(g) In order to write a kernel that operates on an image of size 400x900 pixels, you would like to assign one thread to each pixel. You would like your thread blocks to be square and to use the maximum number of threads per block possible on the device (your device has maximum number of threads per block as 1024). How would you select the grid dimensions and block dimensions of your kernel? [6]**

**How we determine the block dimensions of the kernel**

If the maximum number of threads per block is 1024, this is the same as saying that the maximum block size is 1024.

Because the image is 2D we need to make sure that that the product of the  block dimensions does not exceed the maximum block size / number of threads (1024) because each pixel will be given a thread in the block and we need to divide the block dimensions so there is the same number in each.

Also the question states that the blocks should be *“Square”* the $x,y$ dimensions should be the same.

Therefore a valid block size is one where the product of the sides do not exceed the limit of the block size and the dimensions of the block kernel are the same. Therefore a valid block dimension of the kernel could be 32 x 32.

The way that I would calculate the block size would be to check to see if I can use the square root as it would be the perfect size. 

$\sqrt{1024} = 32$

This is the perfect for the block dimensiosn of the kernel.

**BLOCK SIZE = 32, 32**

**How we determine the grid dimensions of the kernel**

If we want to map a thread for every pixel then the total number of threads in each dimension should be at least equal to the corresponding image dimension. This means the total number of threads in a dimension is equal to the product of grid size and block size in that dimension.

Because the image size is (400x900) pixels the total number of threads in the corresponding dimension **should be the at the very least, the same but can be larger.**

The number of blocks in each dimension would be dimension pixel size / dimension block size. 

x = 400 / 32 = 12.5 so we ceil the result (round up) to get 13.
y = 900 / 32 = 28.125 so we ceil the result (round up) to get 29.

Grid size will be 13 * 29 so total number of threads will be 416 * 928.

Because the grid size will cause the total number of threads to be larger than the total number of pixels I would implement checks to make sure that thread is within the bounds of the dimensions of the image.

**GRID DIMENSIONS = 13 * 29**

**OVERALL ANS:**

**GRID DIMENSIONS = (13 x 29)**

**BLOCK SIZE = (32 x 32)**

## Question 2

See files:

a. **Q2a_6621182.cu**

b. **Q2b_6621182.cu**

c. **Q2c_6621182.cu**

d. **Q2d_6621182.cu**

e. **Q2e_6621182.cu**



## Question 3

![image-20220502112222897](/user/HS402/je00452/Desktop/Parallel Computing Coursework/report_6621182.assets/image-20220502112222897.png)

#### a. **Left image**

​	i. **Maximum degree of concurrency** - The maximum number of concurrent operations that can occur

There are 8 child nodes of the root node therefore 8 nodes that can run concurrent operations. This is the maximum degree of concurrency.

**ANS = 8**

​	ii. **Critical path length** - The sum of weights of nodes along critical path.

There are 7 nodes that are on the critical path - the root node and the 6 other nodes that extend down from that. 

**ANS = 7**

iii. **Average degree of concurrency (express this as a ratio)** - Total amount of work / critical path length

There are 14 nodes therefore toal work = 14, the critical path length is 7, so average degree of concurrency = **14 / 7** 

**ANS = 14 / 7**

#### b. **Right image**

​	i. **Maximum degree of concurrency** - The maximum number of concurrent operations that can occur

With eager scheduling there are 2 nodes that are children of the parents therefore maximum degree of concurrency is 2. Without using the eager scheduling the maximum degree of concurrency is 8 as there are 8 possible nodes that can perform concurrent operartions.

**ANS = 2 with eager scheduling, 8 otherwise** 

​	ii. **Critical path**  - The sum of weights of nodes along critical path.

Along the critical path (the right path) there are 8 nodes which is the critical path.

**ANS = 8** 

​	iii. **Average degree of concurrency (express this as a ratio)** - Total amount of work / critical path length

**ANS = 15 / 8 **

## Question 4

a. See file **Q4a_6621182.cu**

**b. How many global memory reads and writes are performed by your kernel? Explain**

The kernel will be ran (number of threads per block * number of blocks) and each time therefore **will be a read (number of threads per block * number of blocks) times**, but will only be a write after all threads in the block have completed their section so **there will be (number of blocks) writes.**

**ANS:**

**Reads = number of blocks * number of threads per block**

**Writes = number of blocks**

**c. Describe what optimizations were performed to your kernel to achieve a performance speedup.**

I used shared memory within each block to speed up the memory accesses.

**d. Describe what further optimizations can be implemented to your kernel to achieve a performance speedup.**

